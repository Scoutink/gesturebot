[![authors](https://i.imgur.com/gBYmm8n.png)](https://arxiv.org/abs/2102.12302)
[![video demonstration](https://i.imgur.com/rqYRYam.png)](https://www.youtube.com/watch?v=jhgUBS0125A)

We present a framework for integrating data-driven gesture generation models into embodied conversational agents in Unity.

# Instructions for running the Blenderbot demo
*Note: For the other demo with DialogFlow integration, visit the `dialogflow_demo` branch.*



# Source code for the Unity project
The source code of the Unity project is available [on this link](https://drive.google.com/file/d/1OTHe-0IaVKN2WRWusZlE9q259qOihXxj/view?usp=sharing).
The authors would like to thank [Lewis King](https://lewisbenking.github.io/) for sharing the source code of his JimBot project with us.

## Citing

If you use this code in your research please cite it:
```
@inproceedings{Nagy2021gesturebot,
author = {Nagy, Rajmund and Kucherenko, Taras and Moell, Birger and Pereira, Andr\'{e} and Kjellstr\"{o}m, Hedvig and Bernardet, Ulysses},
title = {A Framework for Integrating Gesture Generation Models into Interactive Conversational Agents},
year = {2021},
isbn = {9781450383073},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
booktitle = {Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems},
location = {Virtual Event, United Kingdom},
series = {AAMAS '21}
}
```
